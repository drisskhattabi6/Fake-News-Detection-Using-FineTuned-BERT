#  Fake News Detection using Fine-tuned BERT

This project demonstrates how to fine-tune a pre-trained BERT model to detect fake news articles using a labeled dataset. It includes data preprocessing, model training, evaluation, and deployment via a Flask web app.

---

## ğŸ“ Project Structure

```

â”œâ”€â”€ Finetuning-BERT-Fake-News-Detection.ipynb   # Main notebook for training the model
â”œâ”€â”€ Testing\_BERT.ipynb                          # Notebook for testing and evaluation
â”œâ”€â”€ app.py                                      # Flask web application
â”œâ”€â”€ a1\_True.csv                                 # Dataset of real news articles
â”œâ”€â”€ a2\_Fake.csv                                 # Dataset of fake news articles
â”œâ”€â”€ model/
â”‚   â””â”€â”€ fakenews\_weights.pt                     # Another saved model version
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css                               # Styling for the web interface
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html                              # Home page for news submission
â”‚   â””â”€â”€ result.html                             # Result page for prediction
â”œâ”€â”€ logs.log                                    # Log file during training or testing
â””â”€â”€ README.md                                   # This file

````

---

## ğŸ§ª Dataset

The dataset consists of two CSV files:

- `a1_True.csv` â€“ real news articles
- `a2_Fake.csv` â€“ fake news articles

Each file includes the text of the news and associated metadata. The data is preprocessed and combined for training.

---

## ğŸ§  Model

- **Model Used:** [`bert-base-uncased`](https://huggingface.co/bert-base-uncased)
- **Architecture:**
  - Pre-trained BERT encoder
  - Linear â†’ ReLU â†’ Dropout â†’ Linear â†’ LogSoftmax
- **Loss Function:** Negative Log Likelihood Loss (`NLLLoss`)
- **Optimizer:** `AdamW` with a learning rate of `1e-5`
- **Output Classes:** `Real` or `Fake`


-> Fine-tuning BERT model process :

![Screenshot](imgs/process.png)

---

### ğŸ“ˆ Evaluation

After fine-tuning the BERT model on the fake news dataset, the classifier achieved the following performance metrics on the test set:

```
              precision    recall  f1-score   support

       Real       0.84      0.92      0.88      3213
       Fake       0.92      0.84      0.88      3522

    Accuracy                           0.88      6735
   Macro avg       0.88      0.88      0.88      6735
Weighted avg       0.88      0.88      0.88      6735
```

âœ… **Overall Accuracy:** 88%
ğŸ“Š **Balanced Performance:** Both real and fake news are classified with high precision and recall, indicating that the model is not biased toward either class.

---

## ğŸš€ How to Use

### ğŸ”§ 1. Install Requirements

```bash
pip install torch transformers flask
````

### ğŸ‹ï¸ 2. Train or Load the Model

* Use the notebook `Finetuning-BERT-Fake-News-Detection.ipynb` to train and save the model.
* Or use the already fine-tuned model in `cashe/c2_new_model_weights.pt`.

### ğŸŒ 3. Run the Flask Web App

```bash
python app.py
```

Then open your browser and visit: [http://localhost:5000](http://localhost:5000)

---

## ğŸ–¥ï¸ Web Interface

* Paste a news article into the form.
* Click "Check".
* The app will return a prediction: âœ… **Real News** or âŒ **Fake News**


![Screenshot](imgs/img1.png)

![Screenshot](imgs/img2.png)


---

## ğŸ§ª API Endpoint

You can also use the API with a POST request:

```bash
curl -X POST http://localhost:5000/api/predict \
     -H "Content-Type: application/json" \
     -d '{"text": "Some news content here..."}'
```

Response:

```json
{
  "prediction": "Fake News"
}
```

---

## ğŸ™Œ Acknowledgements

* [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
* Hugging Face Transformers
* PyTorch
